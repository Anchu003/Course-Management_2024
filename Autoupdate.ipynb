{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85c61e1-1be5-4483-b20e-e53dbb8b4708",
   "metadata": {},
   "outputs": [],
   "source": [
    "import schedule\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# Hàm lấy dữ liệu mới từ trang web và lưu vào Excel\n",
    "def fetch_and_save_data():\n",
    "    all_data = []\n",
    "    base_url = 'https://www.scrapethissite.com/pages/forms/'\n",
    "\n",
    "    # Kiểm tra xem file Excel đã tồn tại chưa\n",
    "    try:\n",
    "        # Đọc file Excel hiện tại nếu có\n",
    "        df_existing = pd.read_excel(r'D:\\python\\File\\all_table_data.xlsx')\n",
    "        last_update_date = df_existing['Ngày cập nhật'].max()  # Lấy ngày cập nhật cuối cùng\n",
    "        print(f\"Ngày cập nhật cuối cùng là: {last_update_date}\")\n",
    "    except FileNotFoundError:\n",
    "        # Nếu không có file Excel, sử dụng một ngày giả định ban đầu (ví dụ: ngày đầu tiên)\n",
    "        last_update_date = datetime(2000, 1, 1)\n",
    "        print(\"File Excel không tồn tại. Sử dụng ngày giả định.\")\n",
    "\n",
    "    # Lấy nội dung trang đầu tiên để xác định số trang tối đa\n",
    "    response = requests.get(base_url)\n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        pagination = soup.find('ul', class_='pagination')\n",
    "\n",
    "        if pagination:\n",
    "            pages = pagination.find_all('li')\n",
    "            total_pages = int(pages[-2].text.strip())  # Số trang tối đa\n",
    "        else:\n",
    "            print(\"Không tìm thấy phần phân trang.\")\n",
    "            total_pages = 1\n",
    "    else:\n",
    "        print(\"Không thể truy cập trang chính.\")\n",
    "        total_pages = 1\n",
    "    \n",
    "    # Duyệt qua từng trang và thu thập dữ liệu\n",
    "    for page in range(1, total_pages + 1):\n",
    "        url = f'{base_url}?page_num={page}'\n",
    "        response = requests.get(url)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "            table = soup.find('table', class_='table')\n",
    "\n",
    "            if table:\n",
    "                rows = table.find_all('tr')\n",
    "\n",
    "                # Lấy tiêu đề của bảng từ trang đầu tiên\n",
    "                if page == 1:\n",
    "                    headers = [header.text.strip() for header in rows[0].find_all('th')]\n",
    "                \n",
    "                # Lặp qua từng hàng của bảng (trừ hàng tiêu đề)\n",
    "                for row in rows[1:]:\n",
    "                    cols = row.find_all('td')\n",
    "                    data_row = [col.text.strip() for col in cols]\n",
    "                    data_row.append(datetime.now().strftime('%Y-%m-%d %H:%M:%S'))  # Thêm cột ngày cập nhật\n",
    "                    all_data.append(data_row)\n",
    "\n",
    "                print(f\"Đã lấy dữ liệu từ trang {page}\")\n",
    "            else:\n",
    "                print(f\"Không tìm thấy bảng trong trang {page}\")\n",
    "        else:\n",
    "            print(f\"Không thể truy cập trang {page}\")\n",
    "    \n",
    "    # Chuyển đổi danh sách dữ liệu thành DataFrame\n",
    "    df_new = pd.DataFrame(all_data, columns=headers + ['Ngày cập nhật'])\n",
    "\n",
    "    # Loại bỏ các bản ghi đã có trong file Excel (dựa trên cột 'Ngày cập nhật')\n",
    "    if not df_existing.empty:\n",
    "        df_combined = pd.concat([df_existing, df_new])\n",
    "        df_combined = df_combined[df_combined['Ngày cập nhật'] > last_update_date]\n",
    "    else:\n",
    "        df_combined = df_new\n",
    "\n",
    "    # Lưu dữ liệu vào file Excel\n",
    "    df_combined.to_excel(r'D:\\python\\File\\all_table_data.xlsx', index=False)\n",
    "    print(\"Dữ liệu đã được lưu vào file Excel.\")\n",
    "\n",
    "# Đặt lịch để chạy hàm mỗi ngày (hoặc mỗi giờ, mỗi phút tùy ý)\n",
    "schedule.every().day.at(\"00:00\").do(fetch_and_save_data)  # Cập nhật mỗi ngày lúc 00:00 AM\n",
    "\n",
    "# Lặp lại liên tục để kiểm tra xem có công việc nào cần chạy không\n",
    "while True:\n",
    "    schedule.run_pending()  # Kiểm tra các công việc đã lên lịch\n",
    "    time.sleep(60)  # Kiểm tra lại sau mỗi 60 giây\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5581c1f5-caf8-41be-a5a0-22eb44d363cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe256e1-af69-4cdb-889e-fe80df0e9ade",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
